{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure output directories exist\n",
    "output_dir = 'output'\n",
    "checkpoint_dir = 'checkpoint'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "epochs = 1000\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "latent_dim = 100\n",
    "img_size = 64\n",
    "channels = 3\n",
    "num_classes = 2  # Number of classes (0: Bart, 1: Lisa)\n",
    "\n",
    "img_shape = (channels, img_size, img_size)\n",
    "\n",
    "# Check CUDA's presence\n",
    "cuda_is_present = True if torch.cuda.is_available() else False\n",
    "\n",
    "# Define custom dataset class\n",
    "class CartoonDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        # Define class labels for Bart and Lisa\n",
    "        class_labels = {'bart_simpson': 0, 'lisa_simpson': 1}\n",
    "        for sub_dir in class_labels:\n",
    "            sub_dir_path = os.path.join(root_dir, sub_dir)\n",
    "            if os.path.isdir(sub_dir_path):  # Ensure it's a directory\n",
    "                for img_name in os.listdir(sub_dir_path):\n",
    "                    if img_name.endswith('.jpg') or img_name.endswith('.png'):  # Filter valid image files\n",
    "                        self.image_paths.append(os.path.join(sub_dir_path, img_name))\n",
    "                        self.labels.append(class_labels[sub_dir])\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_size, img_size)),  # Ensure all images are resized to img_size x img_size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = CartoonDataset('./datasets/simpsons_dataset_archive/simpsons_dataset/', transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim + latent_dim, 512, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        c = self.label_emb(labels).unsqueeze(2).unsqueeze(3)\n",
    "        z = z.view(z.size(0), latent_dim, 1, 1)\n",
    "        z = torch.cat((z, c), 1)\n",
    "        img = self.model(z)\n",
    "        return img\n",
    "\n",
    "# Define Discriminator\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.label_emb = nn.Embedding(num_classes, img_size * img_size)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(channels + 1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        c = self.label_emb(labels).view(-1, 1, img_size, img_size)\n",
    "        img = torch.cat((img, c), 1)\n",
    "        validity = self.model(img)\n",
    "        return validity.view(validity.size(0), -1)\n",
    "\n",
    "# Initialize models and loss function\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "\n",
    "if cuda_is_present:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(b1, b2))\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(b1, b2))\n",
    "\n",
    "# Training\n",
    "losses = []\n",
    "images_for_gif = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        real_images = Variable(images.type(torch.cuda.FloatTensor if cuda_is_present else torch.FloatTensor))\n",
    "        labels = Variable(labels.type(torch.cuda.LongTensor if cuda_is_present else torch.LongTensor))\n",
    "        real_output = Variable(torch.ones(images.size(0), 1).type(torch.cuda.FloatTensor if cuda_is_present else torch.FloatTensor))\n",
    "        fake_output = Variable(torch.zeros(images.size(0), 1).type(torch.cuda.FloatTensor if cuda_is_present else torch.FloatTensor))\n",
    "\n",
    "        # Training Generator\n",
    "        optimizer_generator.zero_grad()\n",
    "        z = Variable(torch.randn(images.size(0), latent_dim).type(torch.cuda.FloatTensor if cuda_is_present else torch.FloatTensor))\n",
    "        gen_labels = Variable(torch.randint(0, num_classes, (images.size(0),)).type(torch.cuda.LongTensor if cuda_is_present else torch.LongTensor))\n",
    "        generated_images = generator(z, gen_labels)\n",
    "        generator_loss = adversarial_loss(discriminator(generated_images, gen_labels), real_output)\n",
    "        generator_loss.backward()\n",
    "        optimizer_generator.step()\n",
    "\n",
    "        # Training Discriminator\n",
    "        optimizer_discriminator.zero_grad()\n",
    "        discriminator_loss_real = adversarial_loss(discriminator(real_images, labels), real_output)\n",
    "        discriminator_loss_fake = adversarial_loss(discriminator(generated_images.detach(), gen_labels), fake_output)\n",
    "        discriminator_loss = (discriminator_loss_real + discriminator_loss_fake) / 2\n",
    "        discriminator_loss.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch:4d}/{epochs}] [Batch {i:4d}/{len(data_loader)}] ---> \"\n",
    "              f\"[D Loss: {discriminator_loss.item():.6f}] [G Loss: {generator_loss.item():.6f}]\")\n",
    "\n",
    "    losses.append((generator_loss.item(), discriminator_loss.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        image_filename = f'{output_dir}/images/epoch_{epoch}.png'\n",
    "        os.makedirs(f'{output_dir}/images', exist_ok=True)\n",
    "        save_image(generated_images.data[:25], image_filename, nrow=5, normalize=True)\n",
    "        images_for_gif.append(imageio.imread(image_filename))\n",
    "        # Save model checkpoints\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'generator_epoch_{epoch}.pth')\n",
    "        torch.save(generator.state_dict(), checkpoint_path)\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'discriminator_epoch_{epoch}.pth')\n",
    "        torch.save(discriminator.state_dict(), checkpoint_path)\n",
    "\n",
    "# Visualizing the losses at every epoch\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Generator')\n",
    "plt.plot(losses.T[1], label='Discriminator')\n",
    "plt.title(\"Training Losses\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{output_dir}/loss_plot.png')\n",
    "\n",
    "# Creating a gif of generated images at every epoch\n",
    "imageio.mimwrite(f'{output_dir}/generated_images.gif', images_for_gif, fps=len(images_for_gif)/5)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
